{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbfe5d5408ab433ebe7d715f94ddc0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47f2c1e0af0f48d481340401a9babf5b",
              "IPY_MODEL_8761bc9c900642dc9443fc566e5a95d4",
              "IPY_MODEL_3fe480db4e4141089ce84140fbc37435"
            ],
            "layout": "IPY_MODEL_c66e5f7aaa904ce6b30c4fdd6b0114dc"
          }
        },
        "47f2c1e0af0f48d481340401a9babf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f58e8a1d41b496a93e152acdbae686f",
            "placeholder": "​",
            "style": "IPY_MODEL_e6559d64e68347f585fa596c6e1b324b",
            "value": "100%"
          }
        },
        "8761bc9c900642dc9443fc566e5a95d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef994581f2946888629fc45f7bfa43f",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_017e9b87a5704ca9b7d2230439336f0f",
            "value": 170498071
          }
        },
        "3fe480db4e4141089ce84140fbc37435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3c0240118e49a98721a638e1bbbfd7",
            "placeholder": "​",
            "style": "IPY_MODEL_96ab56d74a934dd2b4fd567add36157c",
            "value": " 170498071/170498071 [00:02&lt;00:00, 61099367.35it/s]"
          }
        },
        "c66e5f7aaa904ce6b30c4fdd6b0114dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f58e8a1d41b496a93e152acdbae686f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6559d64e68347f585fa596c6e1b324b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef994581f2946888629fc45f7bfa43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017e9b87a5704ca9b7d2230439336f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc3c0240118e49a98721a638e1bbbfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ab56d74a934dd2b4fd567add36157c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM6UwWXyH4HP",
        "outputId": "e4cf965d-ca0f-442f-c80f-5aa03ad8e44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flax\n",
            "  Downloading flax-0.6.2-py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from flax) (6.0)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from flax) (4.1.1)\n",
            "Collecting tensorstore\n",
            "  Downloading tensorstore-0.1.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.7/dist-packages (from flax) (0.3.23)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.4)\n",
            "Collecting rich>=11.1\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (1.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3.16->flax) (1.7.3)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.16->flax) (5.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.3.16->flax) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax) (1.15.0)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.12.0)\n",
            "Installing collected packages: commonmark, chex, tensorstore, rich, optax, flax\n",
            "Successfully installed chex-0.1.5 commonmark-0.9.1 flax-0.6.2 optax-0.1.3 rich-12.6.0 tensorstore-0.1.28\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jax_resnet\n",
            "  Downloading jax_resnet-0.0.4-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from jax_resnet) (0.3.23)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from jax_resnet) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (from jax_resnet) (0.6.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (3.2.2)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (12.6.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (4.1.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (0.1.3)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.7/dist-packages (from flax->jax_resnet) (0.1.28)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax->jax_resnet) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax->jax_resnet) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax->jax_resnet) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->jax_resnet) (3.3.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax->jax_resnet) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax->jax_resnet) (2.6.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax->jax_resnet) (3.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax->jax_resnet) (5.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->jax_resnet) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->jax_resnet) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->jax_resnet) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->jax_resnet) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax->jax_resnet) (1.15.0)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax->jax_resnet) (0.1.5)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->jax_resnet) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->jax_resnet) (0.1.7)\n",
            "Installing collected packages: jax-resnet\n",
            "Successfully installed jax-resnet-0.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clu\n",
            "  Downloading clu-0.0.7-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 698 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from clu) (1.21.6)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (from clu) (0.6.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from clu) (2.9.2)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from clu) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from clu) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from clu) (21.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from clu) (1.5.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from clu) (4.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from clu) (1.3.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from clu) (0.3.23)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from etils[epath]->clu) (4.1.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->clu) (5.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->clu) (3.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax->clu) (3.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from flax->clu) (6.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax->clu) (0.1.3)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.7/dist-packages (from flax->clu) (0.1.28)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.7/dist-packages (from flax->clu) (12.6.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->clu) (1.0.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->clu) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax->clu) (1.7.3)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax->clu) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax->clu) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax->clu) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->clu) (0.5.5)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax->clu) (0.1.5)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (0.27.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (2.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->clu) (0.38.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->clu) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->clu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->clu) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->clu) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->clu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->clu) (4.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->clu) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->clu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->clu) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->clu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->clu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->clu) (3.2.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (2.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (4.64.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (1.10.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (0.3.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->clu) (1.56.4)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=5802d1b6ebee4509edd5f6bfda9d9d40bc2b14884f52e0a37192c5410f4f61f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: ml-collections, clu\n",
            "Successfully installed clu-0.0.7 ml-collections-0.1.1\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "import matplotlib.pyplot as plt\n",
        "! pip install flax\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, checkpoints\n",
        "import optax\n",
        "import jax\n",
        "from jax import random\n",
        "import jax.numpy as jnp\n",
        "! pip install jax_resnet\n",
        "import jax_resnet\n",
        "from flax.core.frozen_dict import freeze, unfreeze\n",
        "! pip install clu\n",
        "from clu import parameter_overview\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress = True)"
      ],
      "metadata": {
        "id": "qwgQDHP_I3lx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformsSimCLR:\n",
        "    \"\"\"\n",
        "    A stochastic data augmentation module that transforms any given data example randomly\n",
        "    resulting in two correlated views of the same example,\n",
        "    denoted x i and x j, which we consider as a positive pair.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, is_pretrain=True, is_val=False):\n",
        "        self.is_pretrain=is_pretrain\n",
        "        self.is_val=is_val\n",
        "        s = 1\n",
        "        color_jitter = torchvision.transforms.ColorJitter(\n",
        "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
        "        )\n",
        "        self.train_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
        "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
        "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
        "                torchvision.transforms.Lambda(np.array),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.test_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Lambda(np.array),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.is_pretrain:\n",
        "            return self.train_transform(x), self.train_transform(x)\n",
        "        else:\n",
        "            if self.is_val:\n",
        "                return self.test_transform(x)\n",
        "            else:\n",
        "                return self.train_transform(x)"
      ],
      "metadata": {
        "id": "SUiS1o5oJGdJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_dataset = torchvision.datasets.CIFAR10(\n",
        "        './cifar10',\n",
        "        download=True,\n",
        "        transform=TransformsSimCLR(is_pretrain=True, is_val=False),\n",
        "        train=True\n",
        "    )\n",
        "full_supervised_dataset = torchvision.datasets.CIFAR10(\n",
        "        './cifar10',\n",
        "        download=True,\n",
        "        transform=TransformsSimCLR(is_pretrain=False, is_val=False),\n",
        "        train=True\n",
        "    )\n",
        "\n",
        "val_dataset = torchvision.datasets.CIFAR10(\n",
        "        './cifar10',\n",
        "        download=True,\n",
        "        transform=TransformsSimCLR(is_pretrain=False, is_val=True),\n",
        "        train=False\n",
        "    )\n",
        "\n",
        "# Create a labeled dataset with only 1% of the labels\n",
        "import torch\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "sk = StratifiedKFold(n_splits=100, shuffle=True, random_state=0)\n",
        "splits = sk.split(np.zeros(len(full_supervised_dataset)), full_supervised_dataset.targets)\n",
        "_, train_idc = list(splits)[0]\n",
        "\n",
        "supervised_dataset_1p = torch.utils.data.Subset(full_supervised_dataset, train_idc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "dbfe5d5408ab433ebe7d715f94ddc0f5",
            "47f2c1e0af0f48d481340401a9babf5b",
            "8761bc9c900642dc9443fc566e5a95d4",
            "3fe480db4e4141089ce84140fbc37435",
            "c66e5f7aaa904ce6b30c4fdd6b0114dc",
            "4f58e8a1d41b496a93e152acdbae686f",
            "e6559d64e68347f585fa596c6e1b324b",
            "cef994581f2946888629fc45f7bfa43f",
            "017e9b87a5704ca9b7d2230439336f0f",
            "fc3c0240118e49a98721a638e1bbbfd7",
            "96ab56d74a934dd2b4fd567add36157c"
          ]
        },
        "id": "ZYijIVCdJI-U",
        "outputId": "4d755065-a8b8-4e80-9cc6-b1498412d8a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbfe5d5408ab433ebe7d715f94ddc0f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_collate(batch):\n",
        "    if isinstance(batch[0], np.ndarray):\n",
        "        return np.stack(batch)\n",
        "    elif isinstance(batch[0], (tuple,list)):\n",
        "        transposed = zip(*batch)\n",
        "        return [numpy_collate(samples) for samples in transposed]\n",
        "    else:\n",
        "        return np.array(batch)\n",
        "\n",
        "class NumpyLoader(data.DataLoader):\n",
        "    def __init__(self, dataset, batch_size=1,\n",
        "                shuffle=False, sampler=None,\n",
        "                batch_sampler=None, num_workers=0,\n",
        "                pin_memory=False, drop_last=False,\n",
        "                timeout=0, worker_init_fn=None):\n",
        "        super(self.__class__, self).__init__(dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            sampler=sampler,\n",
        "            batch_sampler=batch_sampler,\n",
        "            num_workers=num_workers,\n",
        "            collate_fn=numpy_collate,\n",
        "            pin_memory=pin_memory,\n",
        "            drop_last=drop_last,\n",
        "            timeout=timeout,\n",
        "            worker_init_fn=worker_init_fn)"
      ],
      "metadata": {
        "id": "_V4S9kpJJKWw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_dataloader = NumpyLoader(pretrain_dataset, batch_size=128)"
      ],
      "metadata": {
        "id": "UPlm1jpaJO0a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x1,x2), y = pretrain_dataset[1]\n",
        "print(\"Image x1 shape: \", x1.shape, \n",
        "      \"\\nImage x2 shape: \", x2.shape, \n",
        "      \"\\nclass index y: \", y, \"\\n\")\n",
        "\n",
        "merged_images = np.concatenate([x1,x2], axis=1)\n",
        "plt.imshow(merged_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "-slP79SFJPIh",
        "outputId": "4d03af9a-6baa-482d-c80e-63465974dca1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image x1 shape:  (32, 32, 3) \n",
            "Image x2 shape:  (32, 32, 3) \n",
            "class index y:  9 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fae0a80e690>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderWithProjectionHead(nn.Module):\n",
        "    encoder : nn.Sequential\n",
        "\n",
        "    def setup(self):\n",
        "        self.proj_head = nn.Sequential([\n",
        "            nn.Dense(features=128), \n",
        "            nn.relu, \n",
        "            nn.Dense(features=10)\n",
        "            ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return self.proj_head(x)"
      ],
      "metadata": {
        "id": "taheDCKGJQhk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "    batch_stats: flax.core.FrozenDict\n",
        "\n",
        "def create_train_state(model, params, config, freeze_encoder=False):\n",
        "    if freeze_encoder:\n",
        "        tx = optax.multi_transform({\n",
        "                'zero': zero_grads(), \n",
        "                'sgd': optax.sgd(\n",
        "                    config[\"learning_rate\"], \n",
        "                    config[\"momentum\"],\n",
        "                )\n",
        "            },\n",
        "            freeze({'backbone':'zero', 'head': 'sgd'})\n",
        "        )\n",
        "    else:\n",
        "        tx = optax.sgd(config[\"learning_rate\"], config[\"momentum\"])\n",
        "    return TrainState.create(\n",
        "        apply_fn=model.apply,\n",
        "        params=params[\"params\"],\n",
        "        tx=tx,\n",
        "        batch_stats=params['batch_stats']\n",
        "    )"
      ],
      "metadata": {
        "id": "MTgc94msJY9F"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nu=3\n",
        "jax.nn.one_hot(jnp.array([-1, 3]), num_classes = nu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwlsQfG2mdjo",
        "outputId": "997d6482-ae9f-4209-b6a2-128669f93947"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[0., 0., 0.],\n",
              "             [0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_col = 1\n",
        "t_row = 1\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def apply_model(train_state, X1, X2):\n",
        "    def loss_fn(params):\n",
        "        logits1, _ = train_state.apply_fn(\n",
        "            {\n",
        "                'params': params,\n",
        "                'batch_stats': train_state.batch_stats,\n",
        "            },\n",
        "            X1,\n",
        "            mutable=['batch_stats']\n",
        "        )\n",
        "        logits2, new_state = train_state.apply_fn(\n",
        "            {\n",
        "                'params': params,\n",
        "                'batch_stats': train_state.batch_stats,\n",
        "            },\n",
        "            X2,\n",
        "            mutable=['batch_stats']\n",
        "        )\n",
        "\n",
        "        N, C = logits2.shape\n",
        "        \n",
        "        p_x2_cond_y = jax.nn.softmax(logits2 / t_col, axis=1)\n",
        "        p_x2_cond_y_sum = jnp.sum(p_x2_cond_y, axis=1, keepdims=True)\n",
        "        # shapes=[(42, 128), (42,)]\n",
        "        lhs = p_x2_cond_y / p_x2_cond_y_sum\n",
        "        \n",
        "        p_y_cond_x1 = jax.nn.softmax(logits1 / t_row, axis=0)\n",
        "        p_y_cond_x1_sum = jnp.sum(p_y_cond_x1, axis=0, keepdims=True)\n",
        "        rhs = (\n",
        "            jnp.log(N / C)\n",
        "            + jnp.log(p_y_cond_x1)\n",
        "            - jnp.log(p_y_cond_x1_sum)\n",
        "        )\n",
        "        loss = -jnp.sum(lhs * rhs, axis=1)\n",
        "        return jnp.mean(loss), (new_state['batch_stats'], logits1, logits2)\n",
        "\n",
        "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "    (loss, (batch_stats, logits1, logits2)), grads = grad_fn(train_state.params)\n",
        "\n",
        "    train_state = train_state.apply_gradients(grads=grads, batch_stats=batch_stats)\n",
        "    return (train_state, logits1, logits2), loss\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def apply_model_supervised(state, X, Y):\n",
        "  \"\"\"\n",
        "  Computes gradients, loss and accuracy for a single batch via supervised \n",
        "  training, not self-supervised training.\n",
        "  \"\"\"\n",
        "  tau = 0.5\n",
        "  def loss_fn(params):\n",
        "    logits, new_model_state = state.apply_fn({'params': params, \n",
        "                             'batch_stats': state.batch_stats}, X,\n",
        "                              mutable=['batch_stats'])\n",
        "\n",
        "    labels = jax.nn.one_hot(Y, num_classes=NUM_CLASS)\n",
        "    loss = optax.softmax_cross_entropy(logits, labels).mean()\n",
        "    accuracy = jnp.mean(jnp.argmax(logits, -1) == Y)\n",
        "    return loss, (new_model_state, accuracy)\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, (new_model_state, accuracy)), grads = grad_fn(state.params)\n",
        "  \n",
        "  new_state = state.apply_gradients(\n",
        "      grads=grads, batch_stats=new_model_state['batch_stats'])\n",
        "\n",
        "  return (new_state, accuracy), loss\n",
        "\n",
        "def supervised_epoch(state, train_dl):\n",
        "  \"\"\"\n",
        "  Train for a single epoch with supervised loss.\n",
        "  \"\"\"\n",
        "  \n",
        "  epoch_loss = []\n",
        "  epoch_accuracy = []\n",
        "\n",
        "  train_dl_tqdm = tqdm.tqdm(train_dl)\n",
        "\n",
        "  for step, (X, Y) in enumerate(train_dl_tqdm):\n",
        "\n",
        "    (new_state, accuracy), loss = apply_model_supervised(state, X, Y)\n",
        "    state = new_state\n",
        "    epoch_loss.append(loss)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "    train_dl_tqdm.set_postfix({'train_loss': loss.item(), 'train_acc': accuracy})\n",
        "\n",
        "  return state, jnp.array(epoch_loss).mean(), jnp.array(epoch_accuracy).mean()\n",
        "\n",
        "def pretrain_epoch(train_state, train_dataloader):\n",
        "    epoch_loss = []\n",
        "    \n",
        "    train_dataloader_tqdm = tqdm(train_dataloader)\n",
        "    for step, ((X1,X2), Y) in enumerate(train_dataloader_tqdm):\n",
        "        (train_state, Z1, Z2), loss = apply_model(train_state, X1, X2)\n",
        "        epoch_loss.append(loss)\n",
        "        train_dataloader_tqdm.set_postfix({'train_loss': loss.item()})\n",
        "        \n",
        "    return train_state, np.mean(epoch_loss)\n"
      ],
      "metadata": {
        "id": "02NaDI2aJaO5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://colab.research.google.com/drive/1Y2IiAG69nKQSoIKAOAWC8uypdP7TGFqF?usp=sharing#scrollTo=TqDvTL_tIQCH\n",
        "def zero_grads():\n",
        "    def init_fn(_): \n",
        "        return ()\n",
        "    def update_fn(updates, state, params=None):\n",
        "        return jax.tree_map(jnp.zeros_like, updates), ()\n",
        "    return optax.GradientTransformation(init_fn, update_fn)"
      ],
      "metadata": {
        "id": "rzrczLJHJgso"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def eval_step(state, X, Y):\n",
        "\n",
        "    logits = state.apply_fn({'params': state.params, \n",
        "                             'batch_stats': state.batch_stats}, X,\n",
        "                              mutable=False)\n",
        "    labels = jax.nn.one_hot(Y, num_classes=NUM_CLASS)\n",
        "    loss = optax.softmax_cross_entropy(logits, labels).mean()\n",
        "    accuracy = jnp.mean(jnp.argmax(logits, -1) == Y)\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "def compute_validation_performance(state, val_data_loader):\n",
        "  \"\"\"\n",
        "  Computes the given model's mean loss and accuracy on the validation set.\n",
        "  \"\"\"\n",
        "  val_losses = []\n",
        "  val_accs = []\n",
        "\n",
        "  val_dl_tqdm = tqdm.tqdm(val_data_loader)\n",
        "\n",
        "  for X, Y in val_dl_tqdm:\n",
        "    \n",
        "    loss, accuracy = eval_step(state, X, Y)\n",
        "    val_losses.append(loss)\n",
        "    val_accs.append(accuracy)\n",
        "\n",
        "    val_dl_tqdm.set_postfix({'val_loss': loss.item(), 'val_acc': accuracy.item()})\n",
        "\n",
        "  return jnp.array(val_losses).mean().item(), jnp.array(val_accs).mean().item()"
      ],
      "metadata": {
        "id": "KccKtHMXJlJC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key1 = random.PRNGKey(42)"
      ],
      "metadata": {
        "id": "WYnaHG9lL1E1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLASSIFICATION HEAD\n",
        "# ----- For retriving from Checkpoint------\n",
        "# retrive the checkpoint -> output you get the trainstate of the trained model\n",
        "key2, param_key = random.split(key1)\n",
        "\n",
        "dummy_input = np.zeros((8,32,32,3))\n",
        "\n",
        "# n_classes doesn't matter, we remove the only layer impacted by it anyway.\n",
        "# But we need to pass it to construct a ResNet. \n",
        "base_model = jax_resnet.ResNet18(n_classes=2)\n",
        "\n",
        "base_params = base_model.init(rngs=param_key, x=dummy_input)\n",
        "encoder = EncoderWithProjectionHead(encoder=nn.Sequential(base_model.layers[:-1]))\n",
        "pretrain_params = encoder.init(rngs=param_key, x=dummy_input)\n",
        "\n",
        "config = {\"learning_rate\": 0.01, \"momentum\": 0.9}\n",
        "pretrain_dataloader = NumpyLoader(pretrain_dataset, batch_size=256)\n",
        "pretrain_state = create_train_state(encoder, pretrain_params, config)\n",
        "train_state_encoder_state = flax.training.checkpoints.restore_checkpoint('/work/checkpoint_999', target=pretrain_state)\n",
        "# ----- For retriving from Checkpoint------\n",
        "\n",
        "\n",
        "# print(train_state_encoder_state)\n",
        "# create a encoder model, and initialise them with the parameters from the trained model -> encoder model with the parameters from the trained state\n",
        "trained_encoder = EncoderWithProjectionHead(encoder=nn.Sequential(base_model.layers[:-1]))\n",
        "pretrain_params = trained_encoder.init(rngs=param_key, x=dummy_input)\n",
        "\n",
        "pretrain_params = unfreeze(pretrain_params)\n",
        "pretrain_params['params']['backbone'] = train_state_encoder_state.params\n",
        "pretrain_params['batch_stats']['backbone'] = train_state_encoder_state.batch_stats\n",
        "pretrain_params = freeze(pretrain_params)\n",
        "\n",
        "class AddClassificationLayerToBackbone(nn.Module):\n",
        "    backbone : nn.Sequential\n",
        "    num_classes : int\n",
        "        \n",
        "    def setup(self):\n",
        "        self.head = nn.Sequential([ \n",
        "            nn.Dense(features=self.num_classes, use_bias=False)\n",
        "            ])\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return self.head(x)\n",
        "\n",
        "# use this model to trim the final layer, that is get the encoder and add a classfication head\n",
        "classification_model = AddClassificationLayerToBackbone(backbone=trained_encoder.encoder, num_classes=20)\n",
        "\n",
        "# classification_model\n",
        "finetune_params = classification_model.init(param_key, dummy_input)\n",
        "finetune_params = unfreeze(finetune_params)\n",
        "\n",
        "finetune_params['params']['backbone'] = train_state_encoder_state.params['encoder']\n",
        "finetune_params['batch_stats']['backbone'] = train_state_encoder_state.batch_stats['encoder']\n",
        "finetune_params = freeze(finetune_params)\n",
        "\n",
        "output = classification_model.apply(finetune_params, dummy_input, mutable=False)\n",
        "output.shape, output.dtype\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmfgxPaWJnXT",
        "outputId": "cfe70d40-f307-484e-aa0e-668986b79201"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 20), dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gIsAg-W1ez_F"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supervised_train_dataloader = NumpyLoader(supervised_dataset_1p, batch_size=128)\n",
        "val_dataloader = NumpyLoader(val_dataset, batch_size=128)\n",
        "\n",
        "finetune_config = {\"learning_rate\": 0.01, \"momentum\": 0.9}\n",
        "finetune_state = create_train_state(classification_model, finetune_params, finetune_config, freeze_encoder=True)\n",
        "NUM_CLASS = 20\n",
        "\n",
        "for epoch in range(5):\n",
        "  finetune_state, train_loss, train_acc = supervised_epoch(state=finetune_state, train_dl=supervised_train_dataloader)\n",
        "  print(f\"Epoch {epoch}: train loss {train_loss:.2f}, train accuracy {train_acc:.2f}\")\n",
        "\n",
        "  val_loss, val_acc = compute_validation_performance(finetune_state, val_dataloader)\n",
        "  print(f\"Epoch {epoch}: val loss: {val_loss:.2f}, val accuracy: {val_acc:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "VEDFTmbWQ89M",
        "outputId": "efdddf8b-73d9-4690-fa21-932c67107b71"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 3/4 [00:17<00:05,  5.90s/it, train_loss=3.14, train_acc=0.1015625]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-26bef4687b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mfinetune_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupervised_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinetune_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupervised_train_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}: train loss {train_loss:.2f}, train accuracy {train_acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-16b00bf56912>\u001b[0m in \u001b[0;36msupervised_epoch\u001b[0;34m(state, train_dl)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_model_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         donated_invars=donated_invars, inline=inline, keep_unused=keep_unused)\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_pytree_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_bind_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1953\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m   \u001b[0mfun_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0marg_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_device'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   compiled_fun = xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 235\u001b[0;31m                               keep_unused, *arg_specs)\n\u001b[0m\u001b[1;32m    236\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_stores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     return lower_xla_callable(fun, device, backend, name, donated_invars, False,\n\u001b[0;32m--> 343\u001b[0;31m                               keep_unused, *arg_specs).compile().unsafe_call\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0mxla_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_xla_callable_uncached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m         self._executable = XlaCompiledComputation.from_xla_computation(\n\u001b[1;32m    979\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             **self.compile_args)\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mfrom_xla_computation\u001b[0;34m(name, xla_computation, in_type, out_type, nreps, device, backend, tuple_args, in_avals, out_avals, has_unordered_effects, ordered_effects, kept_var_idx, keepalive, host_callbacks)\u001b[0m\n\u001b[1;32m   1135\u001b[0m                           \"in {elapsed_time} sec\"):\n\u001b[1;32m   1136\u001b[0m       compiled = compile_or_get_cached(backend, xla_computation, options,\n\u001b[0;32m-> 1137\u001b[0;31m                                        host_callbacks)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     buffer_counts = get_buffer_counts(out_avals, ordered_effects,\n\u001b[1;32m   1139\u001b[0m                                       has_unordered_effects)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   return backend_compile(backend, serialized_computation, compile_options,\n\u001b[0;32m-> 1055\u001b[0;31m                          host_callbacks)\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m    992\u001b[0m   \u001b[0;31m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m   \u001b[0;31m# to take in `host_callbacks`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;31m# TODO(phawkins): update users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use this model to trim the final layer, that is get the encoder and add a classfication head\n",
        "num_classes = 20\n",
        "classification_model = AddClassificationLayerToBackbone(backbone=trained_encoder.encoder)\n",
        "# classification_model\n",
        "finetune_params = classification_model.init(param_key, dummy_input)\n",
        "finetune_params = unfreeze(finetune_params)\n",
        "\n",
        "finetune_params['params']['backbone'] = train_state_encoder_state.params['encoder']\n",
        "finetune_params['batch_stats']['backbone'] = train_state_encoder_state.batch_stats['encoder']\n",
        "finetune_params = freeze(finetune_params)\n",
        "\n",
        "finetune_config = {\"learning_rate\": 0.01, \"momentum\": 0.9}\n",
        "finetune_state = create_train_state(classification_model, finetune_params, finetune_config, freeze_encoder=True)\n",
        "\n",
        "for epoch in range(5):\n",
        "  finetune_state, train_loss, train_acc = supervised_epoch(state=finetune_state, train_dl=supervised_train_dataloader)\n",
        "  print(f\"Epoch {epoch}: train loss {train_loss:.2f}, train accuracy {train_acc:.2f}\")\n",
        "\n",
        "  val_loss, val_acc = compute_validation_performance(finetune_state, val_dataloader)\n",
        "  print(f\"Epoch {epoch}: val loss: {val_loss:.2f}, val accuracy: {val_acc:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Qlld6SXsMabm",
        "outputId": "1433db19-887d-47d1-d47b-a63d80aeaa15"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-118054751edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mfinetune_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupervised_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinetune_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupervised_train_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}: train loss {train_loss:.2f}, train accuracy {train_acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: supervised_epoch() got an unexpected keyword argument 'num_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use this model to trim the final layer, that is get the encoder and add a classfication head\n",
        "num_classes = 20\n",
        "classification_model = AddClassificationLayerToBackbone(backbone=trained_encoder.encoder, num_classes=num_classes)\n",
        "# classification_model\n",
        "finetune_params = classification_model.init(param_key, dummy_input)\n",
        "finetune_params = unfreeze(finetune_params)\n",
        "\n",
        "finetune_params['params']['backbone'] = train_state_encoder_state.params['encoder']\n",
        "finetune_params['batch_stats']['backbone'] = train_state_encoder_state.batch_stats['encoder']\n",
        "finetune_params = freeze(finetune_params)\n",
        "\n",
        "finetune_config = {\"learning_rate\": 0.01, \"momentum\": 0.9}\n",
        "finetune_state = create_train_state(classification_model, finetune_params, finetune_config, freeze_encoder=True)\n",
        "\n",
        "for epoch in range(5):\n",
        "  finetune_state, train_loss, train_acc = supervised_epoch(state=finetune_state, train_dl=supervised_train_dataloader, num_classes = num_classes)\n",
        "  print(f\"Epoch {epoch}: train loss {train_loss:.2f}, train accuracy {train_acc:.2f}\")\n",
        "\n",
        "  val_loss, val_acc = compute_validation_performance(finetune_state, val_dataloader)\n",
        "  print(f\"Epoch {epoch}: val loss: {val_loss:.2f}, val accuracy: {val_acc:.2f}\\n\")"
      ],
      "metadata": {
        "id": "WZBn10jrPmGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kWWMtzhP0Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szRaOw_YP67m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftAsIg94QIbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}